{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f0820b",
   "metadata": {},
   "source": [
    "## Academic year: 2021-2022\n",
    "\n",
    "# Mini Project\n",
    "\n",
    "## Goals\n",
    "\n",
    "-   Understanding the translation pattern\n",
    "\n",
    "## Exercise 1.1\n",
    "\n",
    "### Download\n",
    "\n",
    "Download the data from <https://zenodo.org/record/3271358>.\n",
    "\n",
    "View the data contents. As you can see in the output, there are four\n",
    "columns: timestamp, property, language and type.\n",
    "\n",
    "Taking an example line from this dataset,\n",
    "\n",
    "                  2013-09-10T22:43:54Z,P856,en,label             \n",
    "\n",
    "corresponds to the action that an English label of Property P856 was\n",
    "added for the first time at 2013-09-10T22:43:54Z.\n",
    "\n",
    "Following is a description of each column.\n",
    "\n",
    "1.  timestamp: the time at which an action was made. For example,\n",
    "    2013-09-10T22:43:54Z\n",
    "2.  property: Wikidata property identifier. It uses the P-number, For\n",
    "    example, P856\n",
    "3.  language: the language in which a label/description/alias was first\n",
    "    translated\n",
    "4.  type: It could be one of the following values: label, description\n",
    "    and alias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202156ae",
   "metadata": {},
   "source": [
    "### Creation of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c0d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_csv(\"multilingual_wikidata_translation_flow.csv\")\n",
    "\n",
    "# remove duplicates\n",
    "dataframe = dataframe.drop_duplicates()\n",
    "\n",
    "# remove rows with missing values\n",
    "dataframe = dataframe.dropna()\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15161ee1",
   "metadata": {},
   "source": [
    "Get a detailed information of the given dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb79627",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6535a54",
   "metadata": {},
   "source": [
    "Let us now take a look at the translation of labels in different\n",
    "languages for a given property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaee588",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.loc[(dataframe[\"property\"] == \"P856\") & (dataframe[\"type\"] == \"label\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da478f67",
   "metadata": {},
   "source": [
    "We will check the data available for a property like P856.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548d2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptranslation = dataframe.loc[(dataframe[\"property\"] == \"P856\")]\n",
    "print(ptranslation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6e4d6",
   "metadata": {},
   "source": [
    "You can also add additional conditions to filter out any information.\n",
    "The code below filters out the translation of labels of property P856.\n",
    "Please copy the code below and create new cells for testing with\n",
    "different properties and see the results for translation of descriptions\n",
    "and aliases. What are your first observations? Please note them as\n",
    "comments in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b297d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptranslation = dataframe.loc[\n",
    "    (dataframe[\"property\"] == \"P856\") & (dataframe[\"type\"] == \"label\")\n",
    "]\n",
    "print(ptranslation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a53db1d",
   "metadata": {},
   "source": [
    "### Visualization of translation\n",
    "\n",
    "Our next goal is to plot the translation of a property and see whether\n",
    "we can observe any translation pattern. Please copy the code below and\n",
    "create new cells for testing with different properties and plot the\n",
    "results. In this plot, we plot the time on the x-axis and translation\n",
    "type on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d49bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plot\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "\n",
    "ptranslation = dataframe.loc[(dataframe[\"property\"] == \"P856\")]\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "for i in range(0, len(ptranslation[\"timestamp\"])):\n",
    "    # parsing the date in string and converting it to datetime\n",
    "    try:\n",
    "        value = parser.parse(ptranslation[\"timestamp\"].iloc[i])\n",
    "        x.append(value)\n",
    "    except Exception:\n",
    "        continue\n",
    "    y.append(ptranslation[\"type\"].iloc[i])\n",
    "    z.append(ptranslation[\"language\"].iloc[i])\n",
    "\n",
    "# creating  a plot\n",
    "plot.rcParams[\"figure.figsize\"] = (25, 9)\n",
    "colors = matplotlib.cm.rainbow(np.linspace(0, 1, 3))\n",
    "tcolors = {\"label\": colors[0], \"description\": colors[1], \"alias\": colors[2]}\n",
    "cs = [tcolors[i] for i in y]\n",
    "fig, ax = plot.subplots()\n",
    "ax.scatter(x, y, s=30, color=cs)\n",
    "\n",
    "plot.xlabel(\"Time\")\n",
    "plot.ylabel(\"Translation type\")\n",
    "\n",
    "# annotating  the points\n",
    "for i, txt in enumerate(z):\n",
    "    ax.annotate(txt, (x[i], y[i]))\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a84039",
   "metadata": {},
   "source": [
    "Now, we plot another graph, this time, language on the y-axis and time\n",
    "on the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b98319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plot\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "\n",
    "ptranslation = dataframe.loc[(dataframe[\"property\"] == \"P279\")]\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "\n",
    "for i in range(0, len(ptranslation[\"timestamp\"])):\n",
    "    try:\n",
    "        # parsing the date in string and converting it to datetime\n",
    "        value = parser.parse(ptranslation[\"timestamp\"].iloc[i])\n",
    "        x.append(value)\n",
    "    except Exception:\n",
    "        continue\n",
    "    y.append(ptranslation[\"type\"].iloc[i])\n",
    "    z.append(ptranslation[\"language\"].iloc[i])\n",
    "\n",
    "# creating a plot\n",
    "colors = matplotlib.cm.rainbow(np.linspace(0, 1, 3))\n",
    "tcolors = {\"label\": colors[0], \"description\": colors[1], \"alias\": colors[2]}\n",
    "\n",
    "cs = [tcolors[i] for i in y]\n",
    "\n",
    "plot.rcParams[\"figure.figsize\"] = (25, 25)\n",
    "fig, ax = plot.subplots()\n",
    "ax.scatter(x, z, s=50, color=cs)\n",
    "\n",
    "plot.xlabel(\"Time\")\n",
    "plot.ylabel(\"Language\")\n",
    "\n",
    "# saving the plot in a file\n",
    "plot.savefig(\"translation.png\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d142e8b",
   "metadata": {},
   "source": [
    "Check the plots concerning properties: P31, P279 and P856\n",
    "respectively. What are your observations on the values on the y-axis?\n",
    "Please note them as comments on the notebook. You can also see that some\n",
    "translations can be even made in a single edit. Please check a column of\n",
    "red lines in the first figure (P31).\n",
    "\n",
    "![Translation plot of property P31](p31.png)\n",
    "\n",
    "![Translation plot of property P279](p279.png)\n",
    "\n",
    "![Translation plot of property P856](p856.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac34b9c4",
   "metadata": {},
   "source": [
    "In the code given below, we select some languages and see the order of\n",
    "translation. Copy the code below and plot the graphs for different\n",
    "properties. Please note your observations as comments on the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "\n",
    "# list of languages under consideration\n",
    "langlist = [\"fr\", \"es\", \"en\", \"de\", \"it\", \"pt\", \"ja\"]\n",
    "ptranslation = dataframe.loc[\n",
    "    (dataframe[\"property\"] == \"P18\") & (dataframe[\"language\"].isin(langlist))\n",
    "]\n",
    "print(ptranslation)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "\n",
    "for i in range(0, len(ptranslation[\"timestamp\"])):\n",
    "    try:\n",
    "        # parsing the date in string and converting it to datetime\n",
    "        value = parser.parse(ptranslation[\"timestamp\"].iloc[i])\n",
    "        x.append(value)\n",
    "    except Exception:\n",
    "        continue\n",
    "    y.append(ptranslation[\"type\"].iloc[i])\n",
    "    z.append(ptranslation[\"language\"].iloc[i])\n",
    "\n",
    "\n",
    "# creating  a plot\n",
    "colors = matplotlib.cm.rainbow(np.linspace(0, 1, 3))\n",
    "tcolors = {\"label\": colors[0], \"description\": colors[1], \"alias\": colors[2]}\n",
    "\n",
    "cs = [tcolors[i] for i in y]\n",
    "plot.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "fig, ax = plot.subplots()\n",
    "ax.scatter(x, z, s=50, color=cs)\n",
    "\n",
    "plot.savefig(\"translation.png\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05983720",
   "metadata": {},
   "source": [
    "## Exercise 1.2\n",
    "\n",
    "We used plotting techniques to manually detect some patterns of\n",
    "translation. Now we use other algorithms to see whether groups of\n",
    "languages are always present together\n",
    "\n",
    "Before continuing, we need to install the library *mlxtend*.\n",
    "```\n",
    "                 !pip install mlxtend               \n",
    "```\n",
    "Next we prepare the language dataset. We will focus on the translation\n",
    "of property labels. We create a list of list of available translations\n",
    "of labels of all the properties from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbdd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset of languages\n",
    "languageorder = []\n",
    "labeldataframe = dataframe.loc[(dataframe[\"type\"] == \"label\")]\n",
    "groups = labeldataframe.groupby([\"property\"])\n",
    "\n",
    "for k, group in groups:\n",
    "    languageorder.append(list(groups.get_group((k))[\"language\"]))\n",
    "\n",
    "print(languageorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fdfc6a",
   "metadata": {},
   "source": [
    "This will give us the following output.\n",
    "\n",
    "```\n",
    "  [['en', 'it', 'fi', 'fr', 'de', 'zh-hans', 'ru', 'hu', 'he', 'nl', 'pt', 'pl', 'ca', 'cs', 'ilo', 'zh', 'nb', 'ko',..        \n",
    "```\n",
    "\n",
    "Now we calculate the frequent itemsets using *apriori* algorithm. Please\n",
    "uncomment the print statement to see the intermediate dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdba93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(languageorder).transform(languageorder)\n",
    "\n",
    "# preparation of data frame\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# use of apriori algorithm\n",
    "frequent_itemsets = apriori(df, min_support=0.75, use_colnames=True)\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ba073",
   "metadata": {},
   "source": [
    "\n",
    "The program uses a minimum support of 0.75. We see that English labels\n",
    "are present for all the properties, whereas French labels are only\n",
    "available for 93% of the properties. On considering pairs of languages,\n",
    "we see that English and Arabic are present in 93% of the translations.\n",
    "As we go further below, we see combinations of 3, 4, 5 languages etc.\n",
    "\n",
    "Please change this value between 0 and 1 and see the output.\n",
    "```\n",
    "\n",
    "      S.No.              support                itemsets\n",
    "      ------- ---------- ---------------------- ----------\n",
    "      0       0.998424   (ar)                   \n",
    "      1       0.759414   (ca)                   \n",
    "      2       1.000000   (en)                   \n",
    "      3       0.932409   (fr)                   \n",
    "      4       0.993540   (nl)                   \n",
    "      5       0.985978   (uk)                   \n",
    "      6       0.758626   (ar, ca)               \n",
    "      7       0.998424   (en, ar)               \n",
    "      8       0.931621   (ar, fr)               \n",
    "      9       0.992752   (nl, ar)               \n",
    "      10      0.985663   (ar, uk)               \n",
    "      11      0.759414   (en, ca)               \n",
    "      12      0.759256   (nl, ca)               \n",
    "      13      0.754215   (uk, ca)               \n",
    "      14      0.932409   (en, fr)               \n",
    "      15      0.993540   (nl, en)               \n",
    "      16      0.985978   (en, uk)               \n",
    "      17      0.931779   (nl, fr)               \n",
    "      18      0.928155   (uk, fr)               \n",
    "      19      0.985663   (nl, uk)               \n",
    "      20      0.758626   (en, ar, ca)           \n",
    "      21      0.758469   (nl, ar, ca)           \n",
    "      22      0.753899   (ar, uk, ca)           \n",
    "      23      0.931621   (en, ar, fr)           \n",
    "      24      0.992752   (nl, en, ar)           \n",
    "      25      0.985663   (en, ar, uk)           \n",
    "      26      0.931149   (nl, ar, fr)           \n",
    "      27      0.927997   (ar, uk, fr)           \n",
    "      28      0.985347   (nl, ar, uk)           \n",
    "      29      0.759256   (nl, en, ca)           \n",
    "      30      0.754215   (en, uk, ca)           \n",
    "      31      0.754057   (nl, uk, ca)           \n",
    "      32      0.931779   (nl, en, fr)           \n",
    "      33      0.928155   (en, uk, fr)           \n",
    "      34      0.985663   (nl, en, uk)           \n",
    "      35      0.927840   (nl, uk, fr)           \n",
    "      36      0.758469   (nl, en, ar, ca)       \n",
    "      37      0.753899   (en, ar, uk, ca)       \n",
    "      38      0.753742   (nl, ar, uk, ca)       \n",
    "      39      0.931149   (nl, en, ar, fr)       \n",
    "      40      0.927997   (en, ar, uk, fr)       \n",
    "      41      0.985347   (nl, en, ar, uk)       \n",
    "      42      0.927682   (nl, ar, uk, fr)       \n",
    "      43      0.754057   (nl, en, uk, ca)       \n",
    "      44      0.927840   (nl, en, uk, fr)       \n",
    "      45      0.753742   (ar, en, ca, nl, uk)   \n",
    "      46      0.927682   (ar, en, fr, nl, uk)   \n",
    "\n",
    "```\n",
    "\n",
    "Repeat the above experiment for descriptions and aliases. What are your\n",
    "observations. Please note them in the notebook as comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed55afbf",
   "metadata": {},
   "source": [
    "## Exercise 1.3\n",
    "\n",
    "Our next goal is to generate the association rules, i.e, rules of the\n",
    "form. *A -\\> C*, where A is the antecedent and C is the consequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa673cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a0b591",
   "metadata": {},
   "source": [
    "It will give us the following output.\n",
    "\n",
    "```\n",
    "      S.No.   antecedents   consequents   antecedent support   consequent support   support    confidence   lift       leverage   conviction\n",
    "      ------- ------------- ------------- -------------------- -------------------- ---------- ------------ ---------- ---------- ------------\n",
    "      0       (de)          (en)          0.479193             0.988966             0.477932   0.997368     1.008496   0.004026   4.192938\n",
    "      1       (de)          (uk)          0.479193             0.960277             0.468789   0.978289     1.018757   0.008631   1.829646\n",
    "      2       (es)          (en)          0.389975             0.988966             0.388556   0.996362     1.007479   0.002884   3.033137\n",
    "      3       (fr)          (en)          0.713272             0.988966             0.708859   0.993812     1.004900   0.003457   1.783181\n",
    "      4       (it)          (en)          0.413934             0.988966             0.413146   0.998096     1.009232   0.003779   5.795082\n",
    "      5       (ru)          (en)          0.301387             0.988966             0.300441   0.996862     1.007984   0.002380   3.516183\n",
    "      6       (en)          (uk)          0.988966             0.960277             0.950189   0.960791     1.000534   0.000507   1.013087\n",
    "      7       (uk)          (en)          0.960277             0.988966             0.950189   0.989494     1.000534   0.000507   1.050303\n",
    "      8       (es)          (uk)          0.389975             0.960277             0.383039   0.982215     1.022845   0.008555   2.233492\n",
    "      9       (fr)          (uk)          0.713272             0.960277             0.689470   0.966630     1.006615   0.004531   1.190362\n",
    "      10      (it)          (uk)          0.413934             0.960277             0.405738   0.980198     1.020745   0.008246   2.005990\n",
    "      11      (ru)          (uk)          0.301387             0.960277             0.300126   0.995816     1.037009   0.010711   9.493695\n",
    "      12      (de, fr)      (en)          0.391393             0.988966             0.391078   0.999195     1.010343   0.004003   13.698770\n",
    "      13      (de, uk)      (en)          0.468789             0.988966             0.467686   0.997646     1.008777   0.004069   4.687894\n",
    "```\n",
    "        \n",
    "Let's take a look at one of the association rule *(de, fr)-\\>(en)*. The\n",
    "confidence score is 0.999195. But this rule states that when we have\n",
    "French and German translations available, we will also have the English\n",
    "translation.\n",
    "\n",
    "You can change the metric to 'lift' and test.\n",
    "\n",
    "We will now add two columns that will contain the length of antecedents\n",
    "and consequents. As you may have noticed, association rules are\n",
    "dataframes. So we can easily write filter conditions to get antecedents\n",
    "and consequents of length more than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f33d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "arules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.95)\n",
    "\n",
    "arules[\"antecedent_len\"] = arules[\"antecedents\"].apply(lambda x: len(x))\n",
    "arules[\"consequent_len\"] = arules[\"consequents\"].apply(lambda x: len(x))\n",
    "\n",
    "arules.loc[(arules[\"antecedent_len\"] > 1) & (arules[\"consequent_len\"] > 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f2045a",
   "metadata": {},
   "source": [
    "```\n",
    "      S.No.   antecedents   consequents   antecedent support   consequent support   support    confidence   lift       leverage   conviction   antecedent\\_len   consequent\\_len\n",
    "      ------- ------------- ------------- -------------------- -------------------- ---------- ------------ ---------- ---------- ------------ ----------------- -----------------\n",
    "      32      (de, fr)      (en, uk)      0.391393             0.950189             0.383670   0.980266     1.031653   0.011772   2.524088     2                 2\n",
    "      35      (fr, es)      (en, uk)      0.332755             0.950189             0.326765   0.981999     1.033477   0.010585   2.767124     2                 2\n",
    "      38      (fr, it)      (en, uk)      0.345523             0.950189             0.338430   0.979471     1.030817   0.010117   2.426342     2                 2\n",
    "```\n",
    "Repeat the above experiment for translation of descriptions and aliases.\n",
    "Please note down your observations as comments in your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3427f3",
   "metadata": {},
   "source": [
    "## Exercise 1.4\n",
    "\n",
    "Our next goal is to visualize the flow of translation. For this purpose,\n",
    "we install holoviews and bokeh.\n",
    "\n",
    "```\n",
    "    !pip install holoviews bokeh --upgrade             \n",
    "```\n",
    "\n",
    "First, we create groups for different translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "languageorder = []\n",
    "labeldataframe = dataframe.loc[(dataframe[\"type\"] == \"label\")]\n",
    "\n",
    "groups = labeldataframe.groupby([\"property\"])\n",
    "\n",
    "for k, group in groups:\n",
    "    languageorder.append(list(groups.get_group((k))[\"language\"]))\n",
    "\n",
    "languagepairs = []\n",
    "for lo in languageorder:\n",
    "    for i in range(0, len(lo) - 1):\n",
    "        languagepairs.append([lo[i], lo[i + 1], 1])\n",
    "\n",
    "lpdataframe = pd.DataFrame(languagepairs)\n",
    "lpdataframe.columns = [\"source\", \"target\", \"count\"]\n",
    "\n",
    "groups = lpdataframe.groupby([\"source\", \"target\"]).count().reset_index()\n",
    "\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69241e1e",
   "metadata": {},
   "source": [
    "Next we visualize them using circular layout. Note the code below, we\n",
    "have only taken 500 combinations of language pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef7b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "G = nx.from_pandas_edgelist(groups[:500], \"source\", \"target\")\n",
    "\n",
    "plot.rcParams[\"figure.figsize\"] = (15, 15)\n",
    "\n",
    "pos = nx.circular_layout(G)\n",
    "\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3054cf9a",
   "metadata": {},
   "source": [
    "Copy the above code and check the flow of translations for any languages\n",
    "of your choice (number of languages \\> 20)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da78b6f1",
   "metadata": {},
   "source": [
    "Use Bokeh/Holoviews chord layout for visualizing the weights as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d90cc",
   "metadata": {},
   "source": [
    "## Exercise 1.5\n",
    "\n",
    "### Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c41fc3f7",
   "metadata": {},
   "source": [
    "Our final goal is to predict the next language(s) that will be\n",
    "translated, given a sequence of available translations.\n",
    "\n",
    "Take for example, let's assume we have seen the following sequences of\n",
    "translation.\n",
    "```\n",
    "                  [['en', 'it', 'fi', 'fr', 'de', 'nl', 'pt', 'pl', 'ca', 'cs']\n",
    "                    ['en', 'it', 'fi', 'fr', 'de', 'ilo', 'zh', 'nb']\n",
    "                    ['ru', 'hu', 'he', 'nl', 'pt', 'pl', 'ca', 'cs'],\n",
    "                    ...              ]            \n",
    "```\n",
    "Once your model has been trained using this data, it may be able to\n",
    "predict the next possible translation(s).\n",
    "\n",
    "**Example 1**: If the user enters the following sequence,\n",
    "```\n",
    "                  ['pt']             \n",
    "```\n",
    "your model may return the following language\n",
    "```\n",
    "                  ['pl']             \n",
    "```\n",
    "**Example 2**: If the user enters the following sequence,\n",
    "```\n",
    "                  ['it', 'fi']             \n",
    "```\n",
    "your model may return the following language\n",
    "```\n",
    "                  ['fr']\n",
    "```\n",
    "**Example 3**: If the user enters the following sequence,\n",
    "```\n",
    "                  ['nl', 'pt', 'pl']             \n",
    "```\n",
    "your model may return the following languages\n",
    "```\n",
    "                  ['ca', 'cs']             \n",
    "```\n",
    "Your goal in this exercise is to train a neural network model that can\n",
    "predict the next probable translation(s) of labels (or descriptions or\n",
    "aliases).\n",
    "\n",
    "For creating this model, you must use the translation sequence of\n",
    "Wikidata properties seen above. You must split the translation sequences\n",
    "into training and test sequences. Please show the accuracy metrics of\n",
    "your model.\n",
    "\n",
    "It is important that you distinguish among the translation sequences of\n",
    "labels, descriptions and aliases, i.e., the user may ask the next\n",
    "probable language(s) for any of the three.\n",
    "\n",
    "Please comment your code and write down your observations. For example,\n",
    "what's the maximum length of input sequence and output sequence? What's\n",
    "the accuracy metrics? Why did you choose a given neural network model?\n",
    "...\n",
    "\n",
    "**Hint:** You may use recurrent neural network with LSTM (Long\n",
    "short-term memory) or word embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c944373b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
