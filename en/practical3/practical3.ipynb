{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.1: Sentiment Classification with Increasing Neurons\n",
        "**Objective**: Build a simple text classification model to classify movie reviews as positive or negative. Start with a small number of neurons and progressively increase it to observe the effects on performance.\n",
        "\n",
        "**Data**: Use a subset of the IMDB movie review dataset.\n",
        "\n",
        "**Steps**:\n",
        "  1. Start with an `Embedding` layer followed by a `Dense` layer with 16 neurons.\n",
        "  2. Train the model and record the accuracy.\n",
        "  3. Gradually increase the number of neurons in the `Dense` layer (e.g., from 16 to 64 and then 128) and observe how accuracy and training time are affected.\n",
        "  4. Plot the results for accuracy and loss, including for validation tests.\n",
        "\n",
        "Complete the code given below."
      ],
      "metadata": {
        "id": "8_5CliF5f9uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "PDauPHSTibC5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the data\n",
        "vocab_size = 10000  # Only consider the top 10k words\n",
        "max_length = 256    # Pad/truncate all reviews to be 256 words\n",
        "\n",
        "# Load IMDB data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# Pad sequences to the same length\n",
        "x_train = pad_sequences(x_train, maxlen=max_length)\n",
        "x_test = pad_sequences(x_test, maxlen=max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9Ee5DzRie6X",
        "outputId": "79e0b22d-b6f7-4d9d-c648-0260895988c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(dense_neurons):\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Embedding(input_dim=vocab_size, output_dim=64, input_length=max_length),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dense(dense_neurons, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "5wgXwCGvUsiY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron_counts = [16, 64, 128]  # Different sizes for the Dense layer\n",
        "results = {}\n",
        "\n",
        "for neurons in neuron_counts:\n",
        "    print(f\"\\nTraining model with {neurons} neurons in the Dense layer\")\n",
        "    model = build_model(dense_neurons=neurons)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=5,\n",
        "        batch_size=512,\n",
        "        validation_split=0.2,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "    results[neurons] = {'accuracy': accuracy, 'loss': loss}\n"
      ],
      "metadata": {
        "id": "6ipeueguUun5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.2: Fine-grained Image Classification with Increasing Neurons\n",
        "**Objective**: Build a basic image classification model to classify images of flowers (`oxford_flowers102` - the *Oxford 102 Flower Dataset* ). Start with a small number of neurons and progressively increase them to observe the effects on performance.\n",
        "\n",
        "**Data**: Use the Oxford 102 Flower Dataset, which contains images of 102 flower categories.\n",
        "\n",
        "**Steps**:\n",
        "  1. Begin with `Conv2D` and `MaxPooling2D` layers for feature extraction from images.\n",
        "  2. Add a `Flatten` layer to convert 2D feature maps into a 1D vector.\n",
        "  3. Add a `Dense` layer with a small number of neurons (e.g., 32), followed by an output layer.\n",
        "  4. Train the model and record the accuracy.\n",
        "  5. Gradually increase the number of neurons in the `Dense` layer (e.g., from 32 to 128 and then 256) to observe changes in accuracy and training time.\n",
        "\n",
        "Complete the code given below."
      ],
      "metadata": {
        "id": "I3VGLIKtiVxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "UR5TdXBPixMY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Oxford 102 Flower Dataset\n",
        "dataset, info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True)\n",
        "\n",
        "# Split the dataset into training and testing\n",
        "train_dataset = dataset['train']\n",
        "test_dataset = dataset['test']"
      ],
      "metadata": {
        "id": "UV9kuvwDizpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set image parameters\n",
        "image_size = (150, 150)  # Resize images to this size\n",
        "batch_size = 32\n",
        "\n",
        "# Data preprocessing function to resize images and normalize pixel values\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, image_size)\n",
        "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing to the train and test datasets\n",
        "train_dataset = train_dataset.map(preprocess_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.map(preprocess_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "3oUuihUTi4kU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.3 : **Investigating the Influence of Batch Sizes on Model Performance**\n",
        "\n",
        "**Objective**: This exercise will demonstrate how different batch sizes affect the performance of a neural network model, including its training speed, loss, accuracy, and generalization capability.\n",
        "\n",
        "**Dataset**: **Fashion MNIST** — a dataset containing grayscale images of 10 different types of clothing, with 60,000 training images and 10,000 test images.\n",
        "\n",
        "---\n",
        "\n",
        "### Steps:\n",
        "\n",
        "#### 1. **Load the Dataset**\n",
        "   - Use the `tensorflow.keras.datasets.fashion_mnist` to load the dataset.\n",
        "   - Preprocess the data by normalizing the pixel values to the range `[0, 1]`.\n",
        "\n",
        "#### 2. **Define the Model Architecture**\n",
        "   - Build a simple Convolutional Neural Network (CNN) or Fully Connected Neural Network (FCNN) model.\n",
        "   - The model should include:\n",
        "     - An input layer (to handle the 28x28 images).\n",
        "     - One or more hidden layers (e.g., Dense, Conv2D).\n",
        "     - An output layer with 10 units (one for each clothing category).\n",
        "   - Use **softmax activation** for the output layer since it's a multi-class classification problem.\n",
        "\n",
        "#### 3. **Vary the Batch Size**\n",
        "   - Experiment with different batch sizes (e.g., 16, 32, 64, 128, 256).\n",
        "   - For each batch size:\n",
        "     - Train the model for a fixed number of epochs (e.g., 10 epochs).\n",
        "     - Record training loss, validation loss, and accuracy.\n",
        "\n",
        "#### 4. **Train the Model**\n",
        "   - Train the model for each batch size and measure the following:\n",
        "     - **Training time**: How long it takes to complete one epoch.\n",
        "     - **Training and validation loss**: Monitor how the loss changes during training.\n",
        "     - **Accuracy**: Track how well the model performs on the training and validation data.\n",
        "\n",
        "#### 5. **Analyze the Results**\n",
        "   - Compare the following:\n",
        "     - **Training time**: Larger batch sizes may lead to faster training, but they could also lead to diminishing returns in terms of model performance.\n",
        "     - **Loss and accuracy**: Observe how the batch size affects the convergence of the loss function and the accuracy on both training and validation datasets.\n",
        "     - **Overfitting**: Check if smaller batch sizes lead to better generalization (lower validation loss) or if larger batch sizes cause overfitting.\n",
        "\n",
        "#### 6. **Plot the Results**\n",
        "   - Plot graphs comparing training loss, validation loss, and accuracy for different batch sizes.\n",
        "   - Plot the training time for different batch sizes.\n"
      ],
      "metadata": {
        "id": "yHWa7oi9VCTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "metadata": {
        "id": "vofqzMkKVBS1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Reshape the images to (28, 28, 1) to match the input shape expected by CNNs\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "fm_yDvjqVYPA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.4: Emotion Classification Using the CREMA-D Dataset\n",
        "\n",
        "**Objective**: Build a model to classify emotions based on audio clips of human speech. This exercise focuses on identifying emotions such as anger, happiness, sadness, and neutral tones, using basic audio preprocessing and a convolutional neural network.\n",
        "\n",
        "**Dataset**: **CREMA-D** (Crowd-sourced Emotional Multimodal Actors Dataset) contains audio clips of actors expressing six emotions: anger, disgust, fear, happiness, neutral, and sadness. Although not directly available in `tensorflow_datasets`, it’s small enough to preprocess and load efficiently in TensorFlow.\n",
        "\n",
        "---\n",
        "\n",
        "### Steps:\n",
        "\n",
        "#### 1. **Data Loading and Preprocessing**\n",
        "   - **Load the Dataset**:\n",
        "     - Download the CREMA-D dataset from its [official source](https://github.com/CheyneyComputerScience/CREMA-D).\n",
        "     - Organize the audio files and corresponding emotion labels.\n",
        "   - **Audio Processing**:\n",
        "     - Convert audio waveforms into spectrograms or mel-spectrograms for each audio clip.\n",
        "     - Normalize the spectrograms and pad/truncate them to a consistent length, e.g., 2 seconds.\n",
        "\n",
        "#### 2. **Build a Simple Emotion Classification Model**\n",
        "   - **Convolutional Layers**:\n",
        "     - Start with a `Conv2D` layer to learn spatial patterns in the spectrogram.\n",
        "     - Add additional `Conv2D` layers and `MaxPooling2D` layers to capture higher-level features.\n",
        "   - **Flatten and Dense Layers**:\n",
        "     - Flatten the final output and pass it through one or two `Dense` layers for classification.\n",
        "     - Use a softmax activation in the final `Dense` layer with six output units, one for each emotion class.\n",
        "   - **Compile and Train**:\n",
        "     - Use categorical crossentropy as the loss function and an optimizer like Adam.\n",
        "     - Train the model on the training set, using a validation set to tune performance.\n",
        "\n",
        "#### 3. **Model Evaluation**\n",
        "   - **Accuracy**:\n",
        "     - Evaluate the model’s accuracy on the test set.\n",
        "   - **Confusion Matrix**:\n",
        "     - Generate a confusion matrix to analyze which emotions are well-classified and which are commonly misclassified.\n"
      ],
      "metadata": {
        "id": "c1q5D0iL6Lp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/CheyneyComputerScience/CREMA-D.git"
      ],
      "metadata": {
        "id": "Uut_uMSn62c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define path to CREMA-D dataset (update path accordingly)\n",
        "DATA_PATH = '/content/CREMA-D/AudioWAV'\n",
        "LABELS = {'ANG': 0, 'DIS': 1, 'FEA': 2, 'HAP': 3, 'NEU': 4, 'SAD': 5}"
      ],
      "metadata": {
        "id": "FKqAghja6hWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_audio(file_path, max_length=2.5, sr=16000):\n",
        "    audio, _ = librosa.load(file_path, sr=sr)\n",
        "    # Calculate the desired length in samples\n",
        "    target_length = int(sr * max_length)\n",
        "    # Adjust the audio to the desired length\n",
        "    audio = librosa.util.fix_length(audio, size=target_length)\n",
        "    # Convert audio to a mel-spectrogram\n",
        "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
        "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "    return spectrogram_db\n"
      ],
      "metadata": {
        "id": "a09BTeKV6iyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "def load_data(data_path, labels):\n",
        "    data, targets = [], []\n",
        "    for file_name in os.listdir(data_path):\n",
        "        if file_name.endswith('.wav'):\n",
        "            file_path = os.path.join(data_path, file_name)\n",
        "            label_str = file_name.split('_')[2]  # e.g., \"ANG\", \"DIS\"\n",
        "            if label_str in labels:\n",
        "                spectrogram = preprocess_audio(file_path)\n",
        "                data.append(spectrogram)\n",
        "                targets.append(labels[label_str])\n",
        "    return np.array(data), np.array(targets)"
      ],
      "metadata": {
        "id": "aT28mxSh6rQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "X, y = load_data(DATA_PATH, LABELS)\n",
        "X = X[..., np.newaxis]  # Add channel dimension for Conv2D\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SOuPbGmW6x8j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
