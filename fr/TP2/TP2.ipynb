{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travaux pratiques 2\n",
    "\n",
    "**Année: 2024-2025**\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "1. **Modélisation de connaissances et interrogation de données** : Utiliser un langage logique pour structurer une base de connaissances et créer des règles permettant d’extraire des informations spécifiques à partir des données.\n",
    "\n",
    "2. **Classification de textes et d'images** : Concevoir et entraîner des modèles de réseaux de neurones pour la classification de textes (exercice 2.2) et d'images (exercice 2.4), en maîtrisant le prétraitement des données, l'optimisation des hyperparamètres, et l'évaluation des performances des modèles.\n",
    "\n",
    "3. **Prédiction de séquences** : Développer un modèle de prédiction pour des séquences de traductions, en appliquant des techniques de préparation de données séquentielles et en évaluant les performances du modèle sur des données de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Faits\n",
    "    - `eleve(Nom, Prenom, DateNaissance)`: Informations personnelles des élèves.\n",
    "    - `groupe_projet(Eleve, Groupe)`: Groupes de projet auxquels les élèves appartiennent.\n",
    "    - `note(Eleve, Module, Note)`: Notes des élèves dans différents modules.\n",
    "    - `module(NomModule, Description)`: Liste des modules avec leur nom et description.\n",
    "- Règles\n",
    "    - `eleves_groupe(Groupe, Eleves)`: Trouver tous les élèves d’un groupe de projet spécifique.\n",
    "    - `moyenne_notes(Eleve, Module, Moyenne)`: Calculer la moyenne des notes d’un élève dans un module.\n",
    "    - `modules_suivis(Eleve, Modules)`: Lister les modules suivis par un élève.\n",
    "\n",
    "- Exemples de requetes pour questionner la base de connaissance:\n",
    "    - `?- eleves_groupe('Groupe1', Eleves).`\n",
    "    - `?- moyenne_notes('Dupont', 'Math', Moyenne).`\n",
    "    - `?- modules_suivis('Martin', Modules).`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/rodologie/Library/Python/3.12/lib/python/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.3)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/rodologie/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets.reuters import load_data\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de séquence d'entraînement après tokenisation et padding :\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Label correspondant :\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_lenths = [len(x) for x in x_train]\n",
    "plt.hist(x_train_lenths, bins=len(x_train_lenths))\n",
    "\n",
    "max_words = 10000\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words)\n",
    "\n",
    "word_index = tf.keras.datasets.reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text])\n",
    "\n",
    "train_sequences = tokenizer.sequences_to_texts(x_train)\n",
    "test_sequences = tokenizer.sequences_to_texts(x_test)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sequences)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sequences)\n",
    "\n",
    "maxlen = 256\n",
    "train_padded = pad_sequences(train_sequences, maxlen=maxlen, padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=maxlen, padding='post')\n",
    "\n",
    "print(\"Exemple de séquence d'entraînement après tokenisation et padding :\")\n",
    "print(train_padded[0])\n",
    "print(\"Label correspondant :\")\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Chargement et prétraitement des données** : \n",
    "   - Chargez le jeu de données **Reuters** à l’aide de `tf.keras.datasets.reuters`.\n",
    "   - Prétraitez les données en veillant à convertir les textes en séquences de tokens numériques compatibles avec le modèle. Utilisez des techniques comme la tokenisation et le padding pour obtenir des séquences de longueur uniforme.\n",
    "   - **Conseils** : Utilisez `Tokenizer` de `tf.keras.preprocessing.text` pour transformer les textes en séquences numériques et `pad_sequences` pour uniformiser la longueur des séquences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des séquences train : (8982, 442)\n",
      "Taille des séquences test : (2246, 442)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "# Chargement des données Reuters\n",
    "(num_words, test_split) = 10000, 0.2  # Configurations\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
    "    num_words=num_words, test_split=test_split)\n",
    "\n",
    "# Convertir les indices de mots en texte brut pour pouvoir appliquer Tokenizer\n",
    "word_index = reuters.get_word_index()\n",
    "index_to_word = {value: key for key, value in word_index.items()}\n",
    "train_text = [\" \".join([index_to_word.get(i - 3, \"?\")\n",
    "                       for i in item]) for item in train_data]\n",
    "test_text = [\" \".join([index_to_word.get(i - 3, \"?\")\n",
    "                      for i in item]) for item in test_data]\n",
    "\n",
    "# Initialisation du Tokenizer\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "# Transformation des textes en séquences numériques\n",
    "train_sequences = tokenizer.texts_to_sequences(train_text)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_text)\n",
    "\n",
    "# Application du padding pour uniformiser la longueur des séquences\n",
    "# Optionnel : définir une longueur max\n",
    "\n",
    "# Calcul d'une longueur de séquence optimale (par exemple, 95e percentile)\n",
    "sequence_lengths = [len(seq) for seq in train_sequences]\n",
    "max_length = int(np.percentile(sequence_lengths, 95))  # 95e percentile\n",
    "\n",
    "# Application du padding avec cette longueur maximale\n",
    "train_padded = pad_sequences(\n",
    "    train_sequences, maxlen=max_length, padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Vérification des nouvelles dimensions\n",
    "print(\"Taille des séquences train :\", train_padded.shape)\n",
    "print(\"Taille des séquences test :\", test_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Construction d’un modèle de réseau de neurones** : \n",
    "   - Créez un modèle de réseau de neurones profond pour la classification des textes. Expérimentez avec différents types de couches pour trouver une architecture adaptée (par exemple, couches d'embedding pour les mots, couches denses, ou couches LSTM ou GRU pour capturer la structure des séquences).\n",
    "   - **Conseils** : Essayez d’abord une architecture simple (comme une combinaison d’Embedding et Dense), puis explorez l’ajout de couches récurrentes pour une meilleure compréhension du contexte des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">442</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m442\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m640,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             │         \u001b[38;5;34m5,934\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">654,254</span> (2.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m654,254\u001b[0m (2.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">654,254</span> (2.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m654,254\u001b[0m (2.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n",
    "\n",
    "# Paramètres du modèle\n",
    "vocab_size = 10000  # Correspond à num_words dans Tokenizer\n",
    "embedding_dim = 64  # Taille de la représentation des mots en vecteurs denses\n",
    "num_classes = max(train_labels) + 1  # Nombre de classes de sortie\n",
    "\n",
    "# Modèle de base\n",
    "# Modèle de base\n",
    "model_1 = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
    "              input_length=max_length),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Construction explicite du modèle (si nécessaire)\n",
    "model_1.build(input_shape=(None, max_length))\n",
    "\n",
    "# Compilation du modèle\n",
    "model_1.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Résumé du modèle\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">442</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m442\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m640,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             │         \u001b[38;5;34m5,934\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">761,262</span> (2.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m761,262\u001b[0m (2.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">761,262</span> (2.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m761,262\u001b[0m (2.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, GRU\n",
    "\n",
    "# Paramètres du modèle\n",
    "vocab_size = 10000  # Nombre de mots uniques dans le vocabulaire\n",
    "embedding_dim = 64  # Dimension des vecteurs d'Embedding\n",
    "max_length = 442  # Longueur des séquences après padding\n",
    "num_classes = 46  # Nombre de classes pour la classification\n",
    "\n",
    "# Construction du modèle\n",
    "model_2 = Sequential([\n",
    "    # Couche d'Embedding : initialisation correcte avec tous les paramètres\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
    "              input_length=max_length),\n",
    "\n",
    "    # Couche LSTM : ajustement des unités et définition du return_sequences\n",
    "    LSTM(128, return_sequences=False),  # Utilisation de 128 unités dans l'LSTM\n",
    "\n",
    "    # Première couche Dense : activation ReLU\n",
    "    Dense(128, activation='relu'),\n",
    "\n",
    "    # Couche de sortie Dense : avec softmax pour la classification multi-classes\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Construction explicite du modèle (si nécessaire)\n",
    "model_2.build(input_shape=(None, max_length))\n",
    "\n",
    "# Compiler le modèle avec l'optimiseur et la fonction de perte\n",
    "model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Afficher un résumé du modèle pour voir si tout est bien initialisé\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">442</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28288</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,620,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,934</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m442\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m640,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28288\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m3,620,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)             │         \u001b[38;5;34m5,934\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,266,926</span> (16.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,266,926\u001b[0m (16.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,266,926</span> (16.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,266,926\u001b[0m (16.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Flatten\n",
    "\n",
    "# Paramètres du modèle\n",
    "vocab_size = 10000  # Nombre de mots uniques dans le vocabulaire\n",
    "embedding_dim = 64  # Dimension des vecteurs d'Embedding\n",
    "max_length = 442  # Longueur des séquences après padding\n",
    "num_classes = 46  # Nombre de classes pour la classification\n",
    "\n",
    "# Construction du modèle\n",
    "model_3 = Sequential([\n",
    "    # Couche d'Embedding : initialisation correcte avec tous les paramètres\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
    "              input_length=max_length),\n",
    "\n",
    "    # Couche LSTM : ajustement des unités et définition du return_sequences\n",
    "    Flatten(),  # Utilisation de 128 unités dans l'LSTM\n",
    "\n",
    "    # Première couche Dense : activation ReLU\n",
    "    Dense(128, activation='relu'),\n",
    "\n",
    "    # Couche de sortie Dense : avec softmax pour la classification multi-classes\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Construction explicite du modèle (si nécessaire)\n",
    "model_3.build(input_shape=(None, max_length))\n",
    "\n",
    "# Compiler le modèle avec l'optimiseur et la fonction de perte\n",
    "model_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Afficher un résumé du modèle pour voir si tout est bien initialisé\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3589 - loss: 2.5956 - val_accuracy: 0.3829 - val_loss: 2.2652\n",
      "Epoch 2/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4692 - loss: 2.0691 - val_accuracy: 0.5583 - val_loss: 1.8569\n",
      "Epoch 3/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5666 - loss: 1.7696 - val_accuracy: 0.6331 - val_loss: 1.6318\n",
      "Epoch 4/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6277 - loss: 1.5530 - val_accuracy: 0.6541 - val_loss: 1.4720\n",
      "Epoch 5/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6819 - loss: 1.3254 - val_accuracy: 0.6892 - val_loss: 1.3429\n",
      "Epoch 6/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7179 - loss: 1.1904 - val_accuracy: 0.6995 - val_loss: 1.3021\n",
      "Epoch 7/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7324 - loss: 1.1043 - val_accuracy: 0.7208 - val_loss: 1.2025\n",
      "Epoch 8/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7602 - loss: 1.0001 - val_accuracy: 0.7088 - val_loss: 1.1682\n",
      "Epoch 9/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.9078 - val_accuracy: 0.7444 - val_loss: 1.1065\n",
      "Epoch 10/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.8578 - val_accuracy: 0.7418 - val_loss: 1.0715\n",
      "Epoch 1/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 329ms/step - accuracy: 0.3432 - loss: 2.6140 - val_accuracy: 0.2110 - val_loss: 2.4428\n",
      "Epoch 2/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 315ms/step - accuracy: 0.3489 - loss: 2.3876 - val_accuracy: 0.3682 - val_loss: 2.4035\n",
      "Epoch 3/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 283ms/step - accuracy: 0.3510 - loss: 2.4140 - val_accuracy: 0.3664 - val_loss: 2.4049\n",
      "Epoch 4/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 277ms/step - accuracy: 0.3554 - loss: 2.3991 - val_accuracy: 0.3646 - val_loss: 2.4008\n",
      "Epoch 5/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 278ms/step - accuracy: 0.3538 - loss: 2.4189 - val_accuracy: 0.3687 - val_loss: 2.4082\n",
      "Epoch 6/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 287ms/step - accuracy: 0.3541 - loss: 2.4079 - val_accuracy: 0.3638 - val_loss: 2.3962\n",
      "Epoch 7/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 285ms/step - accuracy: 0.3629 - loss: 2.3642 - val_accuracy: 0.3664 - val_loss: 2.4126\n",
      "Epoch 8/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 306ms/step - accuracy: 0.3541 - loss: 2.4146 - val_accuracy: 0.3678 - val_loss: 2.4114\n",
      "Epoch 9/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 278ms/step - accuracy: 0.3561 - loss: 2.3804 - val_accuracy: 0.3664 - val_loss: 2.4128\n",
      "Epoch 10/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 277ms/step - accuracy: 0.3613 - loss: 2.3739 - val_accuracy: 0.3673 - val_loss: 2.4084\n",
      "Epoch 1/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4784 - loss: 2.0796 - val_accuracy: 0.6906 - val_loss: 1.3011\n",
      "Epoch 2/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7925 - loss: 0.8818 - val_accuracy: 0.7373 - val_loss: 1.1657\n",
      "Epoch 3/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9274 - loss: 0.3627 - val_accuracy: 0.7453 - val_loss: 1.1745\n",
      "Epoch 4/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9523 - loss: 0.2179 - val_accuracy: 0.7435 - val_loss: 1.2114\n",
      "Epoch 5/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9564 - loss: 0.1705 - val_accuracy: 0.7329 - val_loss: 1.2694\n",
      "Epoch 6/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9588 - loss: 0.1522 - val_accuracy: 0.7373 - val_loss: 1.2063\n",
      "Epoch 7/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9583 - loss: 0.1292 - val_accuracy: 0.7418 - val_loss: 1.2453\n",
      "Epoch 8/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9605 - loss: 0.1232 - val_accuracy: 0.7293 - val_loss: 1.3682\n",
      "Epoch 9/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9614 - loss: 0.1085 - val_accuracy: 0.7382 - val_loss: 1.2707\n",
      "Epoch 10/10\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9621 - loss: 0.1024 - val_accuracy: 0.7275 - val_loss: 1.3462\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle de base\n",
    "history_1 = model_1.fit(train_padded, train_labels, epochs=10, batch_size=32, validation_data=(test_padded, test_labels))\n",
    "\n",
    "# Entraînement du modèle avec LSTM\n",
    "history_2 = model_2.fit(train_padded, train_labels, epochs=10, batch_size=32, validation_data=(test_padded, test_labels))\n",
    "\n",
    "# Entraînement du modèle avec Flatten\n",
    "history_3 = model_3.fit(train_padded, train_labels, epochs=10, batch_size=32, validation_data=(test_padded, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cherchons maintenant les meilleurs hyper paramètres pour notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "141/141 - 2s - 15ms/step - accuracy: 0.5505 - loss: 1.8458 - val_accuracy: 0.6518 - val_loss: 1.4683\n",
      "Epoch 2/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.7619 - loss: 1.0109 - val_accuracy: 0.7271 - val_loss: 1.2163\n",
      "Epoch 3/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.8936 - loss: 0.4985 - val_accuracy: 0.7453 - val_loss: 1.1677\n",
      "Epoch 4/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9428 - loss: 0.2751 - val_accuracy: 0.7431 - val_loss: 1.1943\n",
      "Epoch 5/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9515 - loss: 0.2108 - val_accuracy: 0.7302 - val_loss: 1.2027\n",
      "Epoch 6/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9506 - loss: 0.1830 - val_accuracy: 0.7306 - val_loss: 1.2438\n",
      "Epoch 7/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9534 - loss: 0.1551 - val_accuracy: 0.7337 - val_loss: 1.2373\n",
      "Epoch 8/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9538 - loss: 0.1482 - val_accuracy: 0.7329 - val_loss: 1.1976\n",
      "Epoch 9/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9531 - loss: 0.1413 - val_accuracy: 0.7373 - val_loss: 1.2867\n",
      "Epoch 10/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9546 - loss: 0.1270 - val_accuracy: 0.7458 - val_loss: 1.2296\n",
      "Epoch 11/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9545 - loss: 0.1238 - val_accuracy: 0.7440 - val_loss: 1.2322\n",
      "Epoch 12/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9545 - loss: 0.1182 - val_accuracy: 0.7431 - val_loss: 1.1759\n",
      "Epoch 13/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9539 - loss: 0.1161 - val_accuracy: 0.7364 - val_loss: 1.2704\n",
      "Epoch 14/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9550 - loss: 0.1129 - val_accuracy: 0.7431 - val_loss: 1.1917\n",
      "Epoch 15/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9557 - loss: 0.1034 - val_accuracy: 0.7235 - val_loss: 1.3504\n",
      "Epoch 16/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9536 - loss: 0.1014 - val_accuracy: 0.7369 - val_loss: 1.2490\n",
      "Epoch 17/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9552 - loss: 0.1017 - val_accuracy: 0.7378 - val_loss: 1.2472\n",
      "Epoch 18/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9545 - loss: 0.0944 - val_accuracy: 0.7306 - val_loss: 1.2471\n",
      "Epoch 19/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9528 - loss: 0.0917 - val_accuracy: 0.7493 - val_loss: 1.2234\n",
      "Epoch 20/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9561 - loss: 0.0883 - val_accuracy: 0.7382 - val_loss: 1.3167\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle avec des hyperparamètres ajustés\n",
    "history = model_rnn.fit(train_padded, train_labels,\n",
    "                    epochs=20,       # Nombre d'époques\n",
    "                    batch_size=64,   # Taille du batch\n",
    "                    # Validation sur l'ensemble de validation\n",
    "                    validation_data=(test_padded, test_labels),\n",
    "                    verbose=2)       # Affichage détaillé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9548 - loss: 0.0886 - val_accuracy: 0.7391 - val_loss: 1.3609 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9565 - loss: 0.0859 - val_accuracy: 0.7431 - val_loss: 1.3115 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9548 - loss: 0.0863 - val_accuracy: 0.7373 - val_loss: 1.3154 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9555 - loss: 0.0866 - val_accuracy: 0.7467 - val_loss: 1.2935 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9565 - loss: 0.0783 - val_accuracy: 0.7337 - val_loss: 1.3911 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9663 - loss: 0.0604 - val_accuracy: 0.7413 - val_loss: 1.4020 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9669 - loss: 0.0562 - val_accuracy: 0.7422 - val_loss: 1.4115 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9650 - loss: 0.0548 - val_accuracy: 0.7427 - val_loss: 1.4283 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9653 - loss: 0.0539 - val_accuracy: 0.7427 - val_loss: 1.4320 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9638 - loss: 0.0532 - val_accuracy: 0.7422 - val_loss: 1.4698 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9680 - loss: 0.0501 - val_accuracy: 0.7418 - val_loss: 1.4680 - learning_rate: 1.0000e-05\n",
      "Epoch 12/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9676 - loss: 0.0501 - val_accuracy: 0.7418 - val_loss: 1.4688 - learning_rate: 1.0000e-05\n",
      "Epoch 13/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9677 - loss: 0.0500 - val_accuracy: 0.7413 - val_loss: 1.4700 - learning_rate: 1.0000e-05\n",
      "Epoch 14/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9682 - loss: 0.0500 - val_accuracy: 0.7409 - val_loss: 1.4710 - learning_rate: 1.0000e-05\n",
      "Epoch 15/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9679 - loss: 0.0499 - val_accuracy: 0.7409 - val_loss: 1.4723 - learning_rate: 1.0000e-05\n",
      "Epoch 16/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9684 - loss: 0.0495 - val_accuracy: 0.7409 - val_loss: 1.4726 - learning_rate: 1.0000e-06\n",
      "Epoch 17/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9684 - loss: 0.0495 - val_accuracy: 0.7409 - val_loss: 1.4727 - learning_rate: 1.0000e-06\n",
      "Epoch 18/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9684 - loss: 0.0495 - val_accuracy: 0.7409 - val_loss: 1.4731 - learning_rate: 1.0000e-06\n",
      "Epoch 19/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9683 - loss: 0.0495 - val_accuracy: 0.7409 - val_loss: 1.4733 - learning_rate: 1.0000e-06\n",
      "Epoch 20/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9684 - loss: 0.0495 - val_accuracy: 0.7409 - val_loss: 1.4736 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Définir un planificateur de taux d'apprentissage (par exemple, diviser par 10 tous les 5 époques)\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch % 5 == 0 and epoch > 0:\n",
    "        return lr * 0.1  # Diviser le taux d'apprentissage par 10\n",
    "    return lr\n",
    "\n",
    "\n",
    "# Appliquer le planificateur lors de l'entraînement\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Entraîner avec le planificateur\n",
    "history = model_rnn.fit(train_padded, train_labels,\n",
    "                    epochs=20,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(test_padded, test_labels),\n",
    "                    verbose=2,\n",
    "                    callbacks=[lr_scheduler])  # Utiliser le planificateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9683 - loss: 0.0495 - val_accuracy: 0.7409 - val_loss: 1.4738\n",
      "Epoch 2/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9682 - loss: 0.0495 - val_accuracy: 0.7409 - val_loss: 1.4740\n",
      "Epoch 3/20\n",
      "141/141 - 2s - 12ms/step - accuracy: 0.9683 - loss: 0.0495 - val_accuracy: 0.7409 - val_loss: 1.4742\n",
      "Epoch 4/20\n",
      "141/141 - 2s - 11ms/step - accuracy: 0.9684 - loss: 0.0495 - val_accuracy: 0.7409 - val_loss: 1.4746\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Définir l'early stopping pour arrêter l'entraînement si la validation n'améliore plus la performance\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model_rnn.fit(train_padded, train_labels,\n",
    "                        epochs=20,\n",
    "                        batch_size=64,\n",
    "                        validation_data=(test_padded, test_labels),\n",
    "                        verbose=2,\n",
    "                        callbacks=[early_stopping])  # Utiliser le planificateur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
